#!/usr/bin/env snakemake


##### MODULES #####


import os
import re
import tarfile
import urllib.request
from collections import defaultdict

import yaml
import snakemake as smk
from snakemake.logging import logger


##### PARAMS #####


# Get the reference directory (must be set)
REF_DIR_KEY = "LCR_MODULES_REF_DIR"
assert REF_DIR_KEY in os.environ, "The `LCR_MODULES_REF_DIR` environment variable is not set."
REF_DIR = os.environ[REF_DIR_KEY].rstrip("/")

# Find available genome builds in `genomes/`
BUILD_YAMLS = [ b for b in os.listdir("./") if b.endswith(".yaml") ]
BUILDS = [ b.replace(".yaml", "") for b in BUILD_YAMLS ]

# List the Gencode releases of interest
GENCODE_RELEASES = ["33"]

# List the read lengths of interest
READ_LENGTHS = [75, 100]

# Configure cvbio UpdateContigNames for different file extensions
CVBIO_CONFIG = {
    "gtf": {"comment": "#", "columns": "0", "skip": "false", "delimiter": "\t"}
}

wildcard_constraints:
    build = "|".join(BUILDS),
    version = "GRCh37|GRCh38",
    gencode_release = "|".join(GENCODE_RELEASES)


##### BUILD MAPPINGS #####


VERSIONS = dict()
SOURCES = dict()
ORIGINAL_FASTAS = dict()

for build in BUILDS:
    with open(f"{build}.yaml") as build_yaml_file:
        build_yaml = yaml.safe_load(build_yaml_file)
        build_info = build_yaml["lcr-modules"]["_shared"]["reference"][build]
        assert "original_genome_fasta" in build_info, f"`{build}` missing `original_genome_fasta`."
        VERSIONS[build] = build_info["version"]
        SOURCES[build] = build_info["source"]
        ORIGINAL_FASTAS[build] = build_info["original_genome_fasta"]


##### CHROMOSOME MAPPINGS #####


# Define method for download ChromosomeMappings repository
def download_chrom_mappings(chrom_mappings_dir):
    chrom_mappings_url = "https://github.com/BrunoGrandePhD/ChromosomeMappings/archive/master.tar.gz"
    tar_file_path = f"{REF_DIR}/ChromosomeMappings.tar.gz"
    os.makedirs(REF_DIR, exist_ok=True)
    urllib.request.urlretrieve(chrom_mappings_url, tar_file_path)
    zip_file = tarfile.open(tar_file_path, "r:gz")
    zip_file.extractall(REF_DIR)
    zip_file.close()
    os.remove(tar_file_path)
    os.rename(f"{REF_DIR}/ChromosomeMappings-master", chrom_mappings_dir)

# Download ChromosomeMappings if not already done
CHROM_MAPPINGS_DIR = f"{REF_DIR}/chrom_mappings"
if not os.path.exists(CHROM_MAPPINGS_DIR):
    download_chrom_mappings(CHROM_MAPPINGS_DIR)

# Find chromosome mappings for human genome
CHROM_MAPPINGS_FILES = os.listdir(CHROM_MAPPINGS_DIR)
CHROM_MAPPINGS_FILES = [ f for f in CHROM_MAPPINGS_FILES if f.startswith("GRCh") ]

TO_SOURCES = set()
CHROM_MAPPINGS = defaultdict(lambda: defaultdict(set))
for chrom_map in CHROM_MAPPINGS_FILES:
    version, from_source, to_source, _ = re.split("[_2.]", chrom_map)
    from_source, to_source = from_source.lower(), to_source.lower()
    CHROM_MAPPINGS[version][to_source].add(from_source)
    # Include the source itself since you can always just use a file as is
    CHROM_MAPPINGS[version][to_source].add(to_source)
    TO_SOURCES.add(to_source)


##### TOOL VERSIONS #####


CONDA_ENVS = {
    "coreutils": "../envs/coreutils/coreutils-8.31.yaml",
    "cvbio": "../envs/cvbio/cvbio-3.0.0.yaml",
    "samtools": "../envs/samtools/samtools-1.9.yaml",
    "bwa": "../envs/bwa/bwa-0.7.17.yaml",
    "star": "../envs/star/star-2.7.3a.yaml",
}

def get_version(path):
    parent_dir, yaml = os.path.split(path)
    yaml_basename, ext = os.path.splitext(yaml)
    package, version = yaml_basename.split("-", 1)
    return version
    
TOOL_VERSIONS = { pkg: get_version(path) for pkg, path in CONDA_ENVS.items() }


##### DOWNLOAD #####


rule download_gencode_annotation:
    output: 
        gtf = REF_DIR + "/downloads/gencode-{gencode_release}/gencode.annotation.{version}.gtf"
    params:
        source = "ucsc"
    run:
        url_parts = [
            "ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human", 
            f"release_{wildcards.gencode_release}"
        ]
        release_fmt = f"v{wildcards.gencode_release}"
        if wildcards.version == "GRCh37":
            url_parts.append("GRCh37_mapping")
            release_fmt += "lift37"
        url_parts.append(f"gencode.{release_fmt}.annotation.gtf.gz")
        url = "/".join(url_parts)
        urllib.request.urlretrieve(url, output.gtf + ".gz")
        shell("gunzip {output.gtf}.gz")


##### FUNCTIONS #####


def get_matching_download_rules(file):
    rule_names = [ r for r in dir(rules) if r.startswith("download_")]
    rule_list = [ getattr(rules, name) for name in rule_names ]
    matching_rules = []
    for r in rule_list:
        # At least one output file should produce
        num_matches = []
        for output_file in r.output:
            matches = smk.io.glob_wildcards(output_file, [file])
            num_matches.append(len(matches[0]))
        if any(num > 0 for num in num_matches):
            matching_rules.append(r)
    return matching_rules


def symlink_same_source(wildcards):

    build = wildcards.build
    suffix = wildcards.suffix
    output_file = f"{REF_DIR}/genomes/{build}/{suffix}"
    raw_download_file = f"{REF_DIR}/downloads/{suffix}"
    
    version = VERSIONS[build]
    to_source = SOURCES[build]
    from_source_options = CHROM_MAPPINGS[version][to_source]
    
    dependencies = []
    matching_rules = get_matching_download_rules(raw_download_file)
    
    for r in matching_rules:
        # The source must be among the ones we can convert from
        if r.params.source not in from_source_options:
            continue
        dependencies.append(r)

    if len(dependencies) == 0:
        msg = f"Could not find rule to generate {output_file}."
        raise Exception(msg)
    
    if len(dependencies) > 1:
        msg = f"Found conflicting rules to generate {output_file}."
        raise Exception(msg)
    
    raw_download_root, raw_download_ext = os.path.splitext(raw_download_file)
    target_download_file = f"{raw_download_root}.{to_source}{raw_download_ext}"
    return target_download_file


def get_cvbio_params(field):

    def get_cvbio_params_custom(wildcards, input, output):

        dependencies = []
        matching_rules = get_matching_download_rules(input.before)
        assert len(matching_rules) == 1, "Not just one matching rule."
        
        dependency = matching_rules[0]
        version = wildcards.version
        from_source = dependency.params.source
        to_source = wildcards.to_source
        file_ext = wildcards.ext
        
        cvbio_params = {
            "mapping": f"{CHROM_MAPPINGS_DIR}/{version}_{from_source}2{to_source}.txt",
            "from_source": from_source,
            "comment": CVBIO_CONFIG[file_ext]["comment"],
            "columns": CVBIO_CONFIG[file_ext]["columns"],
            "skip": CVBIO_CONFIG[file_ext]["skip"],
            "delimiter": CVBIO_CONFIG[file_ext]["delimiter"]
        }
        return cvbio_params[field]
    
    return get_cvbio_params_custom


def get_download_file(file):
    def get_download_file_custom(wildcards):
        build = wildcards.build
        version = VERSIONS[build]
        source = SOURCES[build]
        download_file = file.replace("{version}", version).replace("{source}", source)
        download_file = download_file.replace(REF_DIR, REF_DIR + "/genomes/{build}")
        return download_file
    return get_download_file_custom


##### SHARED #####


rule symlink_download:
    input:
        target = symlink_same_source
    output:
        link = REF_DIR + "/genomes/{build}/downloads/{suffix}"
    conda: CONDA_ENVS["coreutils"]
    shell:
        "ln -srf {input.target} {output.link}"


rule update_contig_names:
    input: 
        before = REF_DIR + "/downloads/{parent_dir}/{prefix}.{version}.{ext}"
    output: 
        after = REF_DIR + "/downloads/{parent_dir}/{prefix}.{version}.{to_source}.{ext}"
    log:
        REF_DIR + "/downloads/{parent_dir}/{prefix}.{version}.{to_source}.{ext}.log"
    params:
        mapping = get_cvbio_params("mapping"),
        from_source = get_cvbio_params("from_source"),
        comment = get_cvbio_params("comment"),
        columns = get_cvbio_params("columns"),
        skip = get_cvbio_params("skip"),
        delimiter = get_cvbio_params("delimiter")
    wildcard_constraints:
        ext = "|".join(CVBIO_CONFIG.keys()),
        to_source = "|".join(TO_SOURCES)
    conda: CONDA_ENVS["cvbio"]
    shell:
        "if [[ '{wildcards.to_source}' == '{params[from_source]}' ]]; then "
            "ln -srf {input.before} {output.after}; "
        "else "
            "cvbio UpdateContigNames --in {input.before} --out {output.after} "
            "--mapping {params.mapping} --comment-chars '{params.comment}' "
            "--columns {params.columns} --skip-missing {params.skip} "
            "--delimiter '{params.delimiter}' > {log} 2>&1; "
        "fi"


##### GENOME BUILDS #####


rule fasta_copy:
    input: lambda wildcards: ORIGINAL_FASTAS[wildcards.build]
    output: REF_DIR + "/genomes/{build}/genome.fa"
    log: REF_DIR + "/genomes/{build}/genome.fa.log"
    shell: "samtools faidx {input} > {log} 2>&1"


rule fasta_index:
    input: REF_DIR + "/genomes/{build}/genome.fa"
    output: REF_DIR + "/genomes/{build}/genome.fa.fai"
    log: REF_DIR + "/genomes/{build}/genome.fa.fai.log"
    conda: CONDA_ENVS["samtools"]
    shell: "samtools faidx {input} > {log} 2>&1"


rule bwa_index_symlink:
    input: REF_DIR + "/genomes/{build}/genome.fa"
    output: REF_DIR + "/genomes/{build}/bwa_index/bwa-{bwa_version}/genome.fa"
    log: REF_DIR + "/genomes/{build}/bwa_index/bwa-{bwa_version}/genome.fa.log"
    conda: CONDA_ENVS["coreutils"]
    shell:
        "ln -srf {input} {output}"


rule bwa_index:
    input: REF_DIR + "/genomes/{build}/bwa_index/bwa-{bwa_version}/genome.fa"
    output: REF_DIR + "/genomes/{build}/bwa_index/bwa-{bwa_version}/genome.fa.bwt"
    log: REF_DIR + "/genomes/{build}/bwa_index/bwa-{bwa_version}/genome.fa.bwt.log"
    conda: CONDA_ENVS["bwa"]
    shell:
        "bwa index {output} > {log} 2>&1"


rule star_index:
    input: 
        fasta = REF_DIR + "/genomes/{build}/genome.fa",
        gtf = get_download_file(rules.download_gencode_annotation.output.gtf)
    output: REF_DIR + "/genomes/{build}/star_index/star-{star_version}/gencode-{gencode_release}/overhang_{overhang}/SA"
    log: REF_DIR + "/genomes/{build}/star_index/star-{star_version}/gencode-{gencode_release}/overhang_{overhang}/SA.log"
    conda: CONDA_ENVS["star"]
    threads: 12
    shell:
        "STAR --runThreadN {threads} --runMode genomeGenerate --genomeDir `dirname {output}` "
        "--genomeFastaFiles {input.fasta} --outTmpDir `dirname {output}`/_STARtmp/ "
        "--sjdbGTFfile {input.gtf} --sjdbOverhang {wildcards.overhang} "
        "--outFileNamePrefix `dirname {output}`/ > {log} 2>&1"


##### TARGETS #####


rule all:
    input:
        fai = expand(
            [
                REF_DIR + "/genomes/{build}/genome.fa.fai",
                REF_DIR + "/genomes/{build}/bwa_index/bwa-{bwa_version}/genome.fa",
                REF_DIR + "/genomes/{build}/star_index/star-{star_version}/gencode-{gencode_release}/overhang_{overhang}/SA",
            ], 
            build=BUILDS,
            bwa_version=TOOL_VERSIONS["bwa"],
            star_version=TOOL_VERSIONS["star"],
            gencode_release=GENCODE_RELEASES,
            overhang=[ l-1 for l in READ_LENGTHS ]
        )
